{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import gzip\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNSObhrvVGZl",
        "outputId": "bcea62df-aa88-490e-f4b6-40881477e335"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    # Load the training and test data from specified paths\n",
        "    train_path = '/content/flatland_train.data'\n",
        "    test_path = '/content/flatland_test.data'\n",
        "\n",
        "    X_train, y_train = pickle.load(gzip.open(train_path, 'rb'))\n",
        "    X_test, y_test = pickle.load(gzip.open(test_path, 'rb'))\n",
        "\n",
        "    # Assign placeholder labels (0) to y_test if needed\n",
        "    y_test = np.zeros(len(X_test), dtype=int)\n",
        "\n",
        "\n",
        "    y_train = np.where(y_train != 0, y_train - 2, y_train)  # Convert labels to 0, 1, 2, 3\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32) / 255.0  # Normalize pixel values\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32) / 255.0\n",
        "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n"
      ],
      "metadata": {
        "id": "4SvwLvwjVGb8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_sobel_filter(X):\n",
        "    # Define Sobel filter kernels for x and y direction\n",
        "    sobel_x = torch.tensor([[-1., 0., 1.],\n",
        "                             [-2., 0., 2.],\n",
        "                             [-1., 0., 1.]], device=X.device).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    sobel_y = torch.tensor([[-1., -2., -1.],\n",
        "                             [0., 0., 0.],\n",
        "                             [1., 2., 1.]], device=X.device).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    # Apply padding to the input images\n",
        "    X_padded = F.pad(X, (1, 1, 1, 1), mode='constant', value=0)  # Padding (left, right, top, bottom)\n",
        "\n",
        "    # Prepare a list to hold the edge images\n",
        "    edge_images = []\n",
        "\n",
        "    # Iterate over the batch of images\n",
        "    for img in tqdm(X_padded, desc=\"Applying Sobel Filter\"):\n",
        "        # Apply Sobel filters to each individual image\n",
        "        edge_x = F.conv2d(img.unsqueeze(0).unsqueeze(0), sobel_x)  # Convolve with sobel_x\n",
        "        edge_y = F.conv2d(img.unsqueeze(0).unsqueeze(0), sobel_y)  # Convolve with sobel_y\n",
        "\n",
        "        # Calculate the magnitude of the gradient\n",
        "        edge_magnitude = torch.sqrt(edge_x ** 2 + edge_y ** 2)\n",
        "\n",
        "        # Normalize to [0, 1] for visibility\n",
        "        edge_magnitude_normalized = edge_magnitude / edge_magnitude.max()\n",
        "\n",
        "        # Store the result and remove the extra dimension if necessary\n",
        "        edge_images.append(edge_magnitude_normalized.squeeze(1))\n",
        "\n",
        "    # Convert the list of edge images back to a tensor\n",
        "    return torch.stack(edge_images)\n"
      ],
      "metadata": {
        "id": "RBBkdeDeVGeP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(X, y):\n",
        "    # Flip images\n",
        "    X_flipped_lr = torch.flip(X, dims=[2])  # Horizontal flip (left-right)\n",
        "    X_flipped_ud = torch.flip(X, dims=[1])  # Vertical flip (up-down)\n",
        "    X_flipped_diag = torch.flip(X_flipped_lr, dims=[1])  # Diagonal flip\n",
        "\n",
        "    # Concatenate original and flipped images\n",
        "    X_augmented = torch.cat((X, X_flipped_lr, X_flipped_ud, X_flipped_diag), dim=0)\n",
        "\n",
        "    # Repeat labels to match augmented data size\n",
        "    y_augmented = torch.cat((y, y, y, y), dim=0)  # Repeat labels 4 times\n",
        "\n",
        "    return X_augmented, y_augmented\n"
      ],
      "metadata": {
        "id": "7CsgVZMhVGgq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataloaders(X_train, y_train, batch_size=32, val_size=0.1):\n",
        "    # Define augmentation transforms for on-the-fly augmentation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(20)\n",
        "    ])\n",
        "\n",
        "    # Split data into train and validation sets\n",
        "    train_size = int((1 - val_size) * len(X_train))\n",
        "    val_size = len(X_train) - train_size\n",
        "    train_data, val_data = random_split(TensorDataset(X_train, y_train), [train_size, val_size])\n",
        "\n",
        "    # Augmented DataLoader for training with transform\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "zFne525fVGi5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 12 * 12, 128)\n",
        "        self.fc2 = nn.Linear(128, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "HYAJAOpcVGlR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_model(net, train_loader, val_loader, epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adadelta(net.parameters(), weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        print(f\"Starting Epoch {epoch + 1}\")\n",
        "\n",
        "        # Training loop\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation loop\n",
        "        net.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = net(images)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        # Scheduler step and average losses\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch + 1} - Training Loss: {running_loss / len(train_loader):.4f}, Validation Loss: {val_loss / len(val_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "sgsvkl7ZVGnT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_predictions(net, X_test, batch_size=64):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.to(device)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).view(-1, 1, 50, 50).to(device)\n",
        "    net.eval()\n",
        "    predictions = []\n",
        "\n",
        "    # Process test data in batches\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X_test_tensor), batch_size):\n",
        "            batch = X_test_tensor[i:i + batch_size]\n",
        "            outputs = net(batch)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())  # Store predictions as a list\n",
        "\n",
        "    # Adjust predictions and format as a single string\n",
        "    predictions = np.where(np.array(predictions) != 0, np.array(predictions) + 2, np.array(predictions))\n",
        "    result_text = ''.join(map(str, predictions))\n",
        "    return result_text\n"
      ],
      "metadata": {
        "id": "R2Rfe4HUVGpt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process the dataset\n",
        "print(\"Loading data...\")\n",
        "X_train, y_train, X_test, y_test = load_data()\n",
        "\n",
        "# Apply Sobel filter to both X_train and X_test\n",
        "print(\"Applying Sobel filter to training and test data...\")\n",
        "X_train = apply_sobel_filter(X_train)\n",
        "X_test = apply_sobel_filter(X_test)\n",
        "\n",
        "# Augment training set\n",
        "print(\"Augmenting training set...\")\n",
        "X_train, y_train = augment_data(X_train, y_train)\n",
        "\n",
        "# Prepare DataLoaders for training and validation\n",
        "print(\"Preparing DataLoaders...\")\n",
        "train_loader, val_loader = prepare_dataloaders(X_train, y_train)\n",
        "\n",
        "# Initialize the model, train, and save the best model\n",
        "print(\"Initializing the model and training...\")\n",
        "net = CNNModel()\n",
        "train_model(net, train_loader, val_loader)\n",
        "\n",
        "# Generate predictions on X_test\n",
        "predictions = generate_predictions(net, X_test)\n",
        "\n",
        "# Convert predictions to a single long text format and print\n",
        "result_text = ''.join(map(str, predictions))\n",
        "print(result_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsrQsiQQVGr9",
        "outputId": "5b50df8d-1776-4c0b-d3bd-a19a3979362d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Applying Sobel filter to training and test data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Applying Sobel Filter: 100%|██████████| 10000/10000 [00:00<00:00, 10517.07it/s]\n",
            "Applying Sobel Filter: 100%|██████████| 10000/10000 [00:00<00:00, 10317.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmenting training set...\n",
            "Preparing DataLoaders...\n",
            "Initializing the model and training...\n",
            "Starting Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Training Loss: 0.6771, Validation Loss: 0.2444\n",
            "Starting Epoch 2\n",
            "Epoch 2 - Training Loss: 0.2786, Validation Loss: 0.2715\n",
            "Starting Epoch 3\n",
            "Epoch 3 - Training Loss: 0.2351, Validation Loss: 0.2365\n",
            "Starting Epoch 4\n",
            "Epoch 4 - Training Loss: 0.2094, Validation Loss: 0.1679\n",
            "Starting Epoch 5\n",
            "Epoch 5 - Training Loss: 0.1918, Validation Loss: 0.1967\n",
            "Starting Epoch 6\n",
            "Epoch 6 - Training Loss: 0.1850, Validation Loss: 0.1798\n",
            "Starting Epoch 7\n",
            "Epoch 7 - Training Loss: 0.1821, Validation Loss: 0.1540\n",
            "Starting Epoch 8\n",
            "Epoch 8 - Training Loss: 0.1782, Validation Loss: 0.4438\n",
            "Starting Epoch 9\n",
            "Epoch 9 - Training Loss: 0.1746, Validation Loss: 0.8135\n",
            "Starting Epoch 10\n",
            "Epoch 10 - Training Loss: 0.1686, Validation Loss: 0.1511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-bc15bcfea631>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).view(-1, 1, 50, 50).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6545533343400053340545465645540463050355560333004363354356664064553303655503043350530654500355355463530403365345345040035360650004655530445455543654345046545535635636546303536656365650360305665463536335363336336465353306053566453360450054500063446060345543400453533456446546354503345300344553655053543306444055363443403030605300054555506334560544330054354500443044350645463346060306564305553645045356533336636330660644345564354536053644433653304055544504505345553050664300303444544504030306344006554333400506636544330334035643434343650403330363543435603556463440550543403430450565505303434536554356435035004453066464556036403330463455363406563043554443345350663053566650564533336350334356344353343060333043443433504546433334036630054450544503543600603355633656300553303033036463444450546453433660605604345456536403330035505464066564430553033365340544530533543635653364030035430440356534344063556033036433354550635036440504640065344340360630645656404363635646435404000565355305364603035300453665355604454550366065300453055344643054505003640633033300355355455363044363454665305346550453446603355040336344366406566034430635645460030055644643436454555666535604534433533403656453455534635504300045363464434440365505440353066633435455505544440035566563444365006455334333654054465343003434456346465433440434444330364534565055636553350466366665444065035404305464055003065363646443506034066346345655363030563035546534303465553566303600330536353435333434335066330534555336543635533063654463544460404363630445655330334564353535300043333343453445054535556334303000404403305345440056456654646036363046453563443444334334364535344333565333446553504546563640503053635565330535553405563434335030303564065630335554353604546560445545334656546034645633405050533554434534053504534406566040353534050034445565535645605453535630533063453436563543544605056506045535044436563044440033640300355503465030335635304543503564033033543435664056553346400556563443446463556044360305553306600055344056563654053560300656335553436354636400330654340433345565444300563355535004040300460065555046566654663363560654545500503003630650436003654440605564505646630346355433505630004404465444333403544403353305434636435445550503645405353043335346063545366004536504054343043033336453304430466340456433534534536333403355666553334454634033053654043354456536650536533346333434535463464434035503535343436364653634550440500435666345606454665640553644340635346054344304443504645543556050034444434435505505546056505054364430550453306065566635536005634355534443355443436333404335360534644440440545463635040636333636444354445040543006605653655360446635564036306434533005445454004534466356330350345040343305300544054345635344534604554430566300406443045344343330335336056053464306403345334556005634436303345550653600660654463533334506505530605454535403560354436456553634040053405553564645535345460353400465565535430003533663334533506546403603630434654540343400453654430433000355655550305343654336630366533660345044400350504444543035603563050306033344565435555030343535346556005546533663660360430535500665335003555054633553303006404450450634554535533463300535503360036660060405034434464335060446450303343443055545544336343330055464646043364344636436445334043030353350433055033603455534653363030644354304633634536330666330045505005653635345635334344404364433545505543543504363456364430445430535344505443000655533404304563404646565353600035505645536635353336406044460044504306453444053003540444443605544543530663430364653560334463546064033535564663345340534036465533560355556644334504545365446435043330000534403446344565465064564063655546056533536530460556530553366543363553453456305045534303640053455356366555536434064504033444343434050564556366435335343633056430044454646560054446633606044355553444330444403453356403504340435330335464553355063505053665400503343035363405346543530544463644305400303550645653340566304453636660043403354334553054500044040500435660540556663334434336336353453544350300356304455553446334043305004353335654660566335543340534444563060645650564536434443453400404005455505436460500000063443330565564665363305643355000553435355655645656433406335063565553500653635654630534444345055343545305656654644306463460036046463034550033543340354543564563503554656055403630566030534404035343554053034363044364045365544355303463566306545363406335534546546653500550646504344500346435643530505536343436300353643530353436606330535535304635565464054634506555366353545345355400430305533554000345360535005653053443654636635650630534606340066305304565354633455355455503600054533434356446356440350530650453503444530334353043044603354035330305350533640405355666543060563433333663636354435463033530643535356430066500034353434554334333065006335554643463563440005464440305003046440443634503300000633634654433533665605655343540005454453634435034463446603640555543540533344640433530543355406440604555644404605530003663553300553533334050334644403600464446450453606646504355350553343646335604355344465540443303500303655540656333503345330533456454450036665053604334340533035435336553535530550563343006003330555604503650663344653353444343653450356545335533503654563304506665535636305444056464503445456556453534336536440406656533060345640545544403630555336443430440603353034634556556344454343330053634304340666403044333433450643535530554563303565553304360336430335065655366063533053460635034533643053064545065036360355364434403564433444543653546504430646436035564533456530303664346033503636400004563555364546663433053043536330443444434545345353456343360353635030063454036330665043460505456545343406653406403335555066043040504443034063506000333653005535035644500656303030065603630653035054353055460453534033546465335333565453553563046305405444433564554604563334034644435660463463063500334500045334336050344466554053533004446655543553633656640334505336503056633453644005663534363303406344503035354304433604636333345630035065355354333003344646665445540045440564543500305553344056334545404344355605545040055334635300554304564403405530555534306344666635535040454454454436343564066633305646650543634053335334450346434300360600534655040034055403404555303435534306645354344665640065354334000650353503650003546535355346350400553433550660034343635030336335564364334536654443540044036303306360554344433033543364443033605035353446336404453306045053060603036563644055540464463055550545444333055544403534354655356400630354460050465545363344350043656055435366634033045360365653505054350435656534435604333433530533363636043000634404665330565033035055345664345634436553363436656453433363543304503443454456645363344340505304503036630553363000633054430503045304005335335340356333430463654655443605544053550346363034035353544044553030334305466364063434460554506643556535343006544030365546560005356333453533003404553354035430466444034553606435543303606665035443353533353366300366536055446456430533333564440564336533353455563665365645400400534054630634305653545560044540456345533434634664536545360355436356633450635445333606563656464364643446356343355535663503560450644446543335604443546033454333406303666665060360350365044034545563400456434534566640536065430463504033443546044300363455345635464350666454450636440355545035350366400645365356404344450453635354353634043650305033063545363046606356355604330543604053465644305533353565333454333354663634354545433345356404404556040405434544454345464333645530336500050535433433630464536335550556636504340045344356466566665034350063335553505430456604345346334443655535660354444543440435406046000654564446436305335544355455343303333345446563453530534653465366650333534053335056336304304000060055640654053344000455644540504066063660543303630503034660036544435354054544653065434033533360406443565306534656534560043343563363656444456664540304650550345605004403606046455653433636355533330303005433456405563556363330534535555005656300366345355004433443540453066530004554664344055436333553345345053634054050634356006506443645446366333333065346655050603565335044356534444050063545304463335643530343343006033545443646653665405655554353435545403605353303536300303455306604463503305550036656530354004364545643440403360303066460443450044534633440603656305364345536435433454464433455000336334504465646643343430405433555534554434430460334463643030544433440334640630345064304443403544533436636563455064443633645533550035304403544045303633604436536403604363550443560300443660340655356450346533003335033366453455545443366460440534430645530345303456645434035366304346305034406003344456003006330665650646033545306463460354403453056534534533300330044646535655555554033505360334500405343464454635565655465503454555554030430005565306334660333036455644500643004450335653563304344034430304635434033303304405454663545064043033430045064550056634453300036344646636436335655565445354053640643034350655333366445650505464503305063353430443643563500553363343565335555654003555650353346400036554033350553036353664456633540463305646453460063600500454363656555364363303604665564363555004440336065640354504530634446446544335664646304033046344355433356633530363444333340353355005605565560435364053556360465006436450436034465436356350546445333534335345033334433063444300534443536600505304650556404454555663545454053033340363045430536056443565454530545505635343664004033543644033560035656556643630604345533504543354534436355345303633564433650654530606366653034653030034340446566604334663365344354453066503534330333530530003533634305350000004554046565404306553443504300635036560663465355645533345663436000345066605333033064453656303666364360666536306335444356354553650666340344505355550466553403455353646055545003033343433440353506633344665405455636056036400305646033553303345305365503465306334436533555006053634453443345035344340636030505453055036333045454006354630655450354430453346455030656535400434350533445035060346565343506646636355033350436054466046365450455444555456543030556344335660003464633635643444030634545404500603046365004636353554506650550504554500350504344534543445334405366366454450464545050655603364046533354654633433440564455444306653000606445605333644035433406430635\n"
          ]
        }
      ]
    }
  ]
}